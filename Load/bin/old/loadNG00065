#!/usr/bin/env python
#pylint: disable=invalid-name
#pylint: disable=multiple-statements
"""
load ADSP Case/Control (NG00065)
"""

from __future__ import with_statement
from __future__ import print_function

import argparse
import json
import csv

from os import path, listdir

from subprocess import check_output, CalledProcessError
from decimal import Decimal

from CBILDataCommon.Util.utils import warning, die, create_dir, xstr, qw
from CBILDataCommon.Util.postgres_dbi import Database
from CBILDataCommon.Util.gus_dbi import fetch_ontology_term_id

def parse_config():
    ''' parse JSON config file '''
    try:
        with open(args.config, 'r') as f:
            data = json.load(f)
         
    except (OSError, IOError) as e: # FileNotFoundError does not exist below python 3.3
        warning("Count not open config file " + args.config)
        die(e)

    return data


def buildTag(field, isStop=False):
    tag = field + '>'
    if isStop:
        return '</' + tag
    return '<' + tag


def validate_preprocess_dir():
    ''' check if directory exists, if not create '''
    directory = config['preprocess_directory']
    if args.verbose:
        warning("Checking for preprocess directory " + directory + ". Will create if does not exist")

    create_dir(directory)


def create_pvalue_dir():
    ''' check if directory exists, if not create '''
    directory = path.join(config['preprocess_directory'], 'pvalue_only')
    
    if args.verbose:
        warning("Checking for pvalue-only directory " + directory + ". Will create if does not exist")

    create_dir(directory)


def create_study_xml():
    ''' uses study config to generate xml file for load gusxml'''
    study = config['study']

    dbh = Database(args.gusConfigFile)
    dbh.connect()
    study['category_id'] = fetch_ontology_term_id(study['category'], dbh)
    dbh.close()
    del study['category']

    study['source_id'] = config['accession']

    if args.verbose: warning("Study Info:", study)

    fileName = path.join(config['preprocess_directory'], 'study.xml')

    with open(fileName, 'w') as f:
        print('<Study::Study>', file=f)
        for field, value in study.iteritems():
            print('\t' + buildTag(field) + xstr(value) + buildTag(field, True), file=f)
        print('</Study::Study>', file=f)
    return fileName


def load_study():
    ''' create and load study xml '''
    fileName = create_study_xml()
    cmd = ['ga', 'GUS::Supported::Plugin::LoadGusXml', '--file', fileName]
    if args.commit:
        cmd.append('--commit')
    warning("EXECUTING: ", ' '.join(cmd))
    try:
        output = check_output(cmd)
        warning(output)
    except CalledProcessError as e:
        die(e)


def extract_gene_pvalues(fileName):
    ''' extract pvalues '''

    warning("Extract P-values for", fileName)
    pvalueFileName = path.join(config['preprocess_directory'], 'pvalue_only' , fileName.replace('.csv', '_pvalues.csv'))
    fields = qw('gene P rho flag_seqMetaErrflag')
    with open(pvalueFileName, 'w') as of:
        print(','.join(fields), file=of)
        with open(path.join(config['file_directory'], fileName), 'r') as f:
            reader = csv.DictReader(f, delimiter=',')
            for row in reader:
                row = {k: xstr(row[k])for  k in row}

                if row['flag_cMAC'] != '0': continue # skip these results

                print(row['gene'], row['P'], row['rho'], row['flag_seqMetaErrflag'], sep=',', file=of)



def preprocess_gene_file(fileName):
    ''' preprocess gene file
    expected header:
    gene,cmaf,cMAC,nsnps,P,rho,flag_cMAC,flag_seqMetaErrflag'''
    loadFileName = path.join(config['preprocess_directory'], fileName.replace('.csv','_niagads_gene_trait_association.csv'))
    warning("Generating load file for", fileName)
    fields = qw('gene_id p_value cumulative_maf cumulative_mac num_snps rho caveat')

    with open(loadFileName, 'w') as of:
        print('|'.join(fields), file=of)
        with open(path.join(config['file_directory'], fileName), 'r') as f:
            reader = csv.DictReader(f, delimiter=',')
            for row in reader:
                row = {k: xstr(row[k])for  k in row}
                caveat = {}
                if row['flag_cMAC'] != '0':
                    caveat['flag_cMAC'] = 'estimated cumulative MAC < 10'
                if row['flag_seqMetaErrflag'] != '0':
                    caveat['flag_seqMeta'] = 'possible p-value calcualtion error'
                if not caveat:
                    caveat = 'NULL'
                else:
                    caveat = json.dumps(caveat)
                print(row['gene'], row['P'], row['cmaf'], row['cMAC'],
                      row['nsnps'], row['rho'], caveat, sep='|', file=of)


def load_gene():
    ''' preprocesses and loads gene results into NIAGADS.GeneTraitAssociation '''
    for fileName in listdir(config['file_directory']):
        if fileName.endswith('csv') and '_sv_' not in fileName:
            if (fileName.startswith('NG00065_adsp') and args.experiment is None) or fileName == args.experiment:
                warning("")
                warning("---------------------------------------------------------------------")
                warning("Processing file:", fileName)
                warning("---------------------------------------------------------------------")

                if args.preprocess:
                    preprocess_gene_file(fileName)
                if args.extractPvalues:
                    extract_gene_pvalues(fileName)
                if not args.preprocess and not args.extractPvalues:
                    baseName = fileName.replace('.csv', '')
                    loadFileName = path.join(config['preprocess_directory'], fileName.replace('.csv','_niagads_gene_trait_association.csv'))
                    cmd = ['ga', 'NiagadsData::Load::Plugin::LoadGeneTraitAssociationResult', '--file', loadFileName]
                    comment = cmd # b/c the quotes are too difficult to track in the rest
                    cmd.extend(['--sourceId', baseName])
                    cmd.extend(['--name', generate_name(baseName)])
                    cmd.extend(['--description', generate_description(baseName)])
                    cmd.extend(['--characteristics', generate_characteristics(baseName)])
                    cmd.extend(['--studySourceId', config['accession']])
                    cmd.extend(['--extDbRlsSpec', config['external_database_release']])
                    # cmd.extend(['--project', 'ADSP'])

                    warning("EXECUTING: ", ' '.join(cmd))

                    cmd.extend(['--comment', '"' + ' '.join(comment) + '"'])

                    if args.commit:
                        cmd.append('--commit')

                    try:
                        output = check_output(cmd)
                        warning(output)
                    except CalledProcessError as e:
                        die(e)


def generate_characteristics(fileName):
    ''' generate characteristics json'''
    chars = {}
    chars['software']= 'ATLAS'
    chars['diagnosis'] = "late onset Alzheimer's Disease"

    pop = None
    model = None
    if '_sv_' in fileName:
        (study, source, pop, sv, model) = fileName.split('_')
    else:
        (study, source, pop, test, vFilter, model) = fileName.split('_')
        vFilter = vFilter.upper()
        if 'CADD' in vFilter:
            chars['filter function'] = vFilter.replace('CADD', 'CADD&ge;')
        elif 'LOF' in vFilter:
            chars['filter function'] = 'LOF'
        else:
            chars['filter function'] = 'VEP ' + vFilter
            
    chars['population'] = populations[pop]
    chars['covariate specification'] = covariates[model]

    return json.dumps(chars)


def generate_name(fileName):
    ''' generate protocol app name based on file name '''
    # Gene: NG00065_adsp-wes_ea_skato_cadd15_m0
    #  
    # Variant: NG00065_adsp-wes_ea_sv_m0
    # study, source, pop, variant, model

    if '_sv_' in fileName:
        (study, source, pop, sv, model) = fileName.split('_')
        model = model.replace('m', 'Model ')
        return 'ADSP Single-Variant Risk Association: ' + populations[pop] + ' (' + model + ')'
    else:
        (study, source, pop, test, vFilter, model) = fileName.split('_')
        vFilter = vFilter.upper()
        if 'CADD' in vFilter:
            vFilter = vFilter.replace('CADD', 'CADD&ge;')
        elif 'LOF' not in vFilter:
            vFilter = 'VEP ' + vFilter

        model = model.replace('m', 'Model ')

        return 'ADSP Gene Risk: ' + populations[pop] + ' (' + model + ';' + vFilter + ')'


def generate_description(fileName):
    ''' generate protocol app node description based on file name '''

    if '_sv_' in fileName:
        (study, source, pop, sv, model) = fileName.split('_')
        description = "test for association between exonic ADSP variants and the risk of late-onset Alzheimer's disease"
        description = description + ' (' + populations[pop] + '); '
        description = description + 'adjusted for ' + covariates[model]
        return description
    else:
        (study, source, pop, test, vFilter, model) = fileName.split('_')
        description = "optimized kernel-regression-based test (SKAT-O) for association between gene-colocated sets of rare exonic ADSP variants and late-onset Alzheimer's disease"
        description = description + ' (' + populations[pop] + '); '
        description = description + 'adjusted for ' + covariates[model] + ' and filtered for variants with '
        vFilter = vFilter.upper()
        if 'CADD' in vFilter:
            vFilter = vFilter.replace('CADD', 'CADD score &ge;')
        elif 'LOF' in vFilter:
            vFilter = 'predicted Loss of Function (LOF) impact (SnpEff)'
        else:
            vFilter = vFilter + ' predicted impact (VEP v80)'

        return description + vFilter


def preprocess_variant_file(fileName):
    ''' generate load file for variant data
        expected header and example row:
        Name,N,Callrate,MAC,CAF,Beta,SE,P,flag_MAC,flag_Callrate
        1:100127893:G:A,395,1,0,0,5.86625537614216,2.28988859637341,0.0104128807104734,1,0 '''

    loadFileName = path.join(config['preprocess_directory'], fileName.replace('.csv','_results_seqvariation.csv'))
    warning("Generating load file for", fileName)
    fields = qw('variant_id p_value pvalue_mant pvalue_exp frequency evidence')

    count = 0
    with open(loadFileName, 'w') as of:
        print('|'.join(fields), file=of)
        with open(path.join(config['file_directory'], fileName), 'r') as f:
            reader = csv.DictReader(f, delimiter=',')
            for row in reader:
                row = {k: xstr(row[k])for  k in row}
                variantId = row['Name']
                evidence = {}
                evidence['call_rate'] = row['Callrate']
                evidence['minor_allele_count'] = row['MAC']
                evidence['beta'] = row['Beta']
                evidence['standard error'] = row['SE']
                evidence['flag'] = {}
                if row['flag_MAC'] != '0':
                    evidence['flag']['MAC'] = 'minor allele count < 10'
                if row['flag_Callrate'] != '0':
                    evidence['flag']['Callrate'] = 'analysis-specific call rate < 0.8'
                if not evidence['flag']:
                    del evidence['flag']

                frequency = row['CAF']

                pvalue = row['P']
                if pvalue == '': continue

                if 'e' in pvalue.lower():
                    pvalue = pvalue.upper() # allows us to handle #'s < 1e-305
                else:
                    pvalue = '%.3E' % Decimal(pvalue)

                pvalueMant = pvalue.split('E')[0]
                pvalueExp = pvalue.split('E')[1]

                logPvalue = "%.5f" % (Decimal(row['P']).log10() * -1)

                print(variantId, xstr(logPvalue), xstr(pvalueMant), xstr(pvalueExp), frequency, json.dumps(evidence), sep='|', file=of)

                count = count + 1
                if (count % 500000 == 0 and args.verbose):
                    warning("Wrote", xstr(count), "rows.")


def extract_variant_pvalues(fileName):
    ''' generate p_value only versions of files '''
    warning("Extract P-values for", fileName)
    pvalueFileName = path.join(config['preprocess_directory'], 'pvalue_only' , fileName.replace('.csv', '_pvalues.csv'))
    fields = qw('Name Beta SE P')
    count = 0
    with open(pvalueFileName, 'w') as of:
        print(','.join(fields), file=of)
        with open(path.join(config['file_directory'], fileName), 'r') as f:
            reader = csv.DictReader(f, delimiter=',')
            for row in reader:
                row = {k: xstr(row[k])for  k in row}

                #if row['flag_MAC'] != '0':
                #    continue # skip these results
                #if row['flag_Callrate'] != '0': 
                #    continue # skip these results

                if row['P'] == '': continue
                print(row['Name'], row['Beta'], row['SE'], row['P'], sep=',', file=of)

                count = count + 1
                if (count % 500000 == 0 and args.verbose):
                    warning("Wrote", xstr(count), "rows.")

def load_variants():
    ''' preprocess and load variant results into Results.SeqVariation '''
    for fileName in listdir(config['file_directory']):
        if fileName.endswith('csv') and '_sv_' in fileName:
            if (fileName.startswith('NG00065_adsp') and args.experiment is None) or fileName == args.experiment:
                warning("")
                warning("---------------------------------------------------------------------")
                warning("Processing file:", fileName)
                warning("---------------------------------------------------------------------")

                if args.preprocess:
                    preprocess_variant_file(fileName)
                if args.extractPvalues:
                    extract_variant_pvalues(fileName)
                if not args.preprocess and not args.extractPvalues:
                    baseName = fileName.replace('.csv', '')
                    loadFileName = path.join(config['preprocess_directory'], fileName.replace('.csv','_results_seqvariation.csv'))
                    cmd = ['ga', 'NiagadsData::Load::Plugin::LoadSeqVariationResult', '--file', loadFileName]
                    cmd.extend(['--checkAltVariantIds', '--ignoreMergedSnps']) 
                    # cmd.extend(['--skipMissingVariants')# for now skip indels
                    comment = cmd # b/c the quotes are too difficult to track in the rest

                    cmd.extend(['--sourceId', baseName])
                    cmd.extend(['--name', generate_name(baseName)])
                    cmd.extend(['--description', generate_description(baseName)])
                    cmd.extend(['--characteristics', generate_characteristics(baseName)])
                    cmd.extend(['--studySourceId', config['accession']])
                    cmd.extend(['--extDbRlsSpec', config['external_database_release']])
                    cmd.extend(['--variantSource', 'ADSP'])

                    
                    # cmd.extend(['--project', 'ADSP'])

                    warning("EXECUTING: ", ' '.join(cmd))

                    cmd.extend(['--comment', '"' + ' '.join(comment) + '"'])

                    if args.commit:
                        cmd.append('--commit')

                    try:
                        output = check_output(cmd)
                        warning(output)
                    except CalledProcessError as e:
                        die(e)



if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="load NG0065 - ADSP Case/Control")
    parser.add_argument('-c', '--config', help="full path to config file", required=True)
    parser.add_argument('--gusConfigFile', help="full path to gusConfig File; if not specified uses $GUS_HOME/config/gus.config")
    parser.add_argument('--preprocess', help="preprocess", action='store_true')
    parser.add_argument('--extractPvalues', help="generate p-value only files", action='store_true')
    parser.add_argument('--commit', help="commit", action='store_true')
    parser.add_argument('--study', help="load study", action='store_true')
    parser.add_argument('--gene', help="load/preprocess gene data", action='store_true')
    parser.add_argument('--experiment', help="load specific experiment; (provide file prefix) if not specified will load all")
    parser.add_argument('--variant', help="load/preprocess variant data", action='store_true')
    parser.add_argument('--verbose', help="run in verbose mode", action='store_true')
    parser.add_argument('--veryVerbose', help="run in very verbose mode", action='store_true')
    args = parser.parse_args()

    populations = {'ea' : 'European',
                   'ha': 'Caribbean Hispanic',
                   'meta': 'meta analysis'}

    covariates = {'m0': 'PCs and sequencing center',
                  'm1': 'PCs, sequencing center, sex, and age at AD onset or last-known dementia-free age (for controls)',
                  'm2': 'PCs, sequencing center, sex, age at AD onset or last-known dementia-free age (for controls), and APOE E2 and E4 genotypes'}
    
    config = parse_config()
    validate_preprocess_dir()
    if args.extractPvalues: create_pvalue_dir() 

    if args.gene: load_gene() 

    if args.study: load_study()

    if args.variant: load_variants()

