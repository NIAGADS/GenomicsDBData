#!/usr/bin/env python
#pylint: disable=invalid-name
#pylint: disable=no-member
'''
Generates load NGHRI GWAS Catalog tsv file
'''


from __future__ import with_statement
from __future__ import print_function

import re
import argparse
import os.path as path
import csv
import json
from decimal import Decimal

from GenomicsDBData.Util.postgres_dbi import Database
from GenomicsDBData.Util.utils import qw, warning, die, xstr, xstrN

VARIANT_MATCH_SQL="""
	SELECT v.variant_id, ref_allele, alt_allele
	FROM NIAGADS.Variant v 
	WHERE bin_index = (SELECT find_bin_index(%s, %s, %s)) AND POSITION = %s
"""

REFSNP_MATCH_SQL = """
     SELECT variant_id, ref_allele, alt_allele
     FROM NIAGADS.Variant 
     WHERE variant_id IN (SELECT find_variant_by_refsnp(%s))
"""

ONTOLOGY_TERM_SQL = "SELECT ontology_term_id FROM SRes.OntologyTerm WHERE source_id IN %s"


def fetch_ontology_term_id(ontologyTermURIs):
    '''
    fetch ontology term id given ontology term ref
    '''

    ontologyTermRefs = tuple([ot.split('/')[-1] for ot in ontologyTermURIs.split(', ')])
   
    ontologyTermIds = []

    cursor = database.cursor()
    cursor.execute(ONTOLOGY_TERM_SQL, (ontologyTermRefs,))
    for record in cursor:
        ontologyTermIds.append(str(record[0]))
    cursor.close()

    if len(ontologyTermIds) is None:
        warning("No terms found for " + ontologyTermRefs + " in database.")
        ontologyTermIds = ["NULL"]

    return ontologyTermIds


def fetch_variant_id_from_position(position, allele):
    '''
    fetch variant_id given a chr and postition
    '''
    key = position.lower()
    if key in variants:
        return variants[key]

    chrom, pos = position.lower().split(':')
    cursor = database.cursor()
    cursor.execute(VARIANT_MATCH_SQL, (chrom, pos, pos, pos))

    matchingVariants = []
    for record in cursor:
        if record['ref_allele'] == allele or record['alt_allele'] == allele:
            matchingVariants.append(record[0])
    cursor.close()

    if len(matchingVariants) == 0:
        die("No matching record for variant " + position.lower() + " - " + allele + " found in database.")

    variants[key] = matchingVariants
    return matchingVariants


def fetch_variant_id(refSnpId, allele):
    '''
    fetch variant_id given a ref snp id (from dbSNP) and an allele
    '''

    key = refSnpId + '_' + xstr(allele)
    if key in variants:
        return variants[key]

    cursor.execute(REFSNP_MATCH_SQL, (refSnpId,)) # to make a single item a tuple you need a trailing comma

    matchingVariants = []
    matchingMarkers = []
    for record in cursor:
        if allele == '?' or allele is None:
            matchingVariants.append(record['variant_id'])
        else:
            if record['ref_allele'] == allele or record['alt_allele'] == allele:
                matchingVariants.append(record['variant_id'])
            matchingMarkers.append(record['variant_id']) # keep track of markers in case no alleles matched

    if len(matchingVariants) == 0:
        warning("No matching record for variant " + refSnpId + " - " + xstr(allele)  + " found in database.")
        if matchingMarkers:
            warning("Mapping result to all variants associated with rsId")
            variants[key] = matchingMarkers
        else:
            variants[key] = None

    else:
        variants[key] = matchingVariants

    return variants[key]


def build_evidence_json(row):
    '''
    build evidence json
    '''
    row = {key : value.replace('"', '&quot;') for key, value in row.iteritems()}
    row = {key : value.replace('|', '-') for key, value in row.iteritems()}
    return json.dumps(row)


def generate_load_file():
    '''
    parse input file and generate load file
    '''

    pattern = re.compile(' \(.+\)')

    fileName = path.join(args.dir, args.fileName)
    outputFile = path.join(args.dir, "preprocess_" + args.fileName)

    with open(outputFile, 'w') as of:
        with open(fileName) as f:
            reader = csv.DictReader(f, delimiter='\t')
            for row in reader:
                snp = row['STRONGEST SNP-RISK ALLELE']
                if 'chr' in snp.lower():
                    if '37' in args.genomeBuild:
                        warning("Skipping positional-based annotation for", snp)
                        continue
                    else:
                        die("TODO If genome build == GRCh38, allow and correct positional-based mapping")

                if ';' in snp or 'haplotype' in snp.lower(): # haplotype
                    warning("Skipping", snp)
                    continue

                if snp.count('-') > 1:
                    warning("Skipping", snp)
                    continue


                if 'rs' not in snp: # there are actually entries with no SNP!!!
                    warning("Uncaught variation for strongest snp:", snp)
                    continue 

                # warning(snp)
                marker = None
                allele = None
                if '-' in snp:
                    marker, allele = snp.split('-')

                refSnpId = 'rs' + row['SNP_ID_CURRENT']
                variantIds = fetch_variant_id(refSnpId, allele)
                
                if variantIds is None:
                    continue

                ontologyTermIds = fetch_ontology_term_id(row['MAPPED_TRAIT_URI'])

                frequency = row['RISK ALLELE FREQUENCY']
                if frequency == 'NR' or frequency == '' or ',' in frequency or not frequency.replace('.','').isdigit(): 
                    frequency = 'NULL'
                elif '-' in frequency: # range
                    frequency = 'NULL'
                elif ' ' in frequency:
                    frequency = frequency.split(' ')[0]
                    
                frequency = re.sub(pattern, '', frequency)

                neglog10p = 'NULL'
                if row['P-VALUE'] != '':
                    neglog10p = re.sub(pattern, '', row['PVALUE_MLOG'])
                    pvalue = re.sub(pattern, '', row['P-VALUE'])
                
                if '\\' in row['P-VALUE (TEXT)']:
                    t = row['P-VALUE (TEXT)']
                    row['P-VALUE (TEXT)'] = t.replace('\\', '-')

                evidence = build_evidence_json(row)

                for v in variantIds:
                    for ot in ontologyTermIds:
                        print('|'.join((xstr(v), xstr(ot), xstrN(allele),
                                        xstrN(frequency), xstrN(neglog10p),
                                        xstrN(pvalue), evidence)), file=of)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="generate load file NHGRI GWAS Catalog tsv file")
    parser.add_argument('-f', '--fileName', help="file name", required=True)
    parser.add_argument('-d', '--dir', help="working directory", required=True)
    parser.add_argument('--genomeBuild', help="genome build (can match by position only if GRCh38", required=True)
    parser.add_argument('--gusConfigFile',
                        help="GUS config file.  If not provided, assumes default: $GUS_HOME/conf/gus.config")

    args = parser.parse_args()

    database = Database(args.gusConfigFile)
    database.connect()

    cursor = database.cursor("RealDictCursor")

    variants = {}
    generate_load_file()

    database.close()


# DATE ADDED TO CATALOG	PUBMEDID	FIRST AUTHOR	DATE	JOURNAL	LINK	STUDY	DISEASE/TRAIT	INITIAL SAMPLE SIZE	REPLICATION SAMPLE SIZE	REGION	CHR_ID	CHR_POS	REPORTED GENE(S)	MAPPED_GENE	UPSTREAM_GENE_ID	DOWNSTREAM_GENE_ID	SNP_GENE_IDS	UPSTREAM_GENE_DISTANCE	DOWNSTREAM_GENE_DISTANCE	STRONGEST SNP-RISK ALLELE	SNPS	MERGED	SNP_ID_CURRENT	CONTEXT	INTERGENIC	RISK ALLELE FREQUENCY	P-VALUE		P-VALUE (TEXT)	OR or BETA	95% CI (TEXT)	PLATFORM [SNPS PASSING QC]	CNV	MAPPED_TRAIT	MAPPED_TRAIT_URI	STUDY ACCESSION
